{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from chainer.functions import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 準備用関数\n",
    "def load_image(path, size=None):\n",
    "    \"\"\"sizeがNoneのときは画像のそのままのサイズで読み込む\"\"\"\n",
    "    img = Image.open(os.path.expanduser(path)).convert(\"RGB\")\n",
    "    if size is not None:\n",
    "        img = img.resize(size, Image.BILINEAR)\n",
    "    return tf.constant(transform_for_train(np.array([np.array(img)[:, :, :3]], dtype=np.float32)))\n",
    "\n",
    "\n",
    "def transform_for_train(img):\n",
    "    \"\"\"\n",
    "    読み込む画像がRGBなのに対し、VGGなどのパラメータがBGRの順なので、順番を入れ替える。\n",
    "    ImageNetの色の平均値を引く。\n",
    "    \"\"\"\n",
    "    return img[..., ::-1] - 120\n",
    "\n",
    "\n",
    "def transform_from_train(img):\n",
    "    \"\"\"\n",
    "    transform_for_trainの逆操作。\n",
    "    \"\"\"\n",
    "    data = img[:, :, ::-1] + 120  # これ、np.uinit8にしてよくね？\n",
    "    return data.clip(0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Conv:\n",
    "    def __init__(self, chainer_conv):\n",
    "        W = chainer_conv.W.data\n",
    "        b = chainer_conv.b.data\n",
    "        self.W = tf.constant(np.transpose(W, [2, 3, 1, 0]))\n",
    "        self.b = tf.constant(b)\n",
    "    \n",
    "    def __call__(self, x, stride=1, activation_fn=tf.nn.relu, padding=\"SAME\"):\n",
    "        y = tf.nn.conv2d(x, self.W, strides=[1, stride, stride, 1], padding=padding) + self.b\n",
    "        return activation_fn(y) if activation_fn else y\n",
    "\n",
    "def avg_pool(x, ksize, stride, padding=\"SAME\"):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, ksize, ksize, 1],\n",
    "                           strides=[1, stride, stride, 1],\n",
    "                           padding=padding)\n",
    "    \n",
    "def load_caffemodel(caffemodel):\n",
    "    print(\"load model... %s\" % caffemodel)\n",
    "    model = caffe.CaffeFunction(caffemodel)\n",
    "    return lambda layer_name: Conv(getattr(model, layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    \"\"\"\n",
    "    特徴量を得るためのモデルのAbstract class\n",
    "    \"\"\"\n",
    "    default_caffemodel = None\n",
    "    default_alpha = None\n",
    "    default_beta = None\n",
    "\n",
    "    def __init__(self, caffemodel=None, alpha=None, beta=None):\n",
    "        self.conv = load_caffemodel(caffemodel or self.default_caffemodel)\n",
    "        self.alpha = alpha or self.default_alpha\n",
    "        self.beta = beta or self.default_beta\n",
    "    \n",
    "        \n",
    "class NIN(BaseModel):\n",
    "    \"\"\"\n",
    "    NINを用いた特徴量\n",
    "    \"\"\"\n",
    "    default_caffemodel = \"nin_imagenet.caffemodel\"\n",
    "    default_alpha = [0., 0., 1., 1.]\n",
    "    default_beta = [1., 1., 1., 1.]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \"\"\"NINの特徴量\"\"\"\n",
    "        x0 = self.conv(\"conv1\")(x, stride=4, padding=\"VALID\")\n",
    "        \n",
    "        y1 = self.conv(\"cccp2\")(self.conv(\"cccp1\")(x0), activation_fn=None)\n",
    "        pool1 = avg_pool(tf.nn.relu(y1), ksize=3, stride=2)\n",
    "        x1 = self.conv(\"conv2\")(pool1, stride=1)\n",
    "        \n",
    "        y2 = self.conv(\"cccp4\")(self.conv(\"cccp3\")(x1), activation_fn=None)\n",
    "        pool2 = avg_pool(tf.nn.relu(y2), ksize=3, stride=2)\n",
    "        x2 = self.conv(\"conv3\")(pool2, stride=1)\n",
    "\n",
    "        y3 = self.conv(\"cccp6\")(self.conv(\"cccp5\")(x2), activation_fn=None)\n",
    "        pool3 = avg_pool(tf.nn.relu(y3), ksize=3, stride=2)\n",
    "        \n",
    "        drop = tf.nn.dropout(pool3, 0.5)\n",
    "        x3 = self.conv(\"conv4-1024\")(drop)\n",
    "        \n",
    "        return [x0, x1, x2, x3]\n",
    "\n",
    "\n",
    "class VGG(BaseModel):\n",
    "    \"\"\"\n",
    "    VGGを用いた特徴量\n",
    "    \"\"\"\n",
    "    default_caffemodel = \"VGG_ILSVRC_16_layers.caffemodel\"\n",
    "    default_alpha = [0., 0., 1., 1.]\n",
    "    default_beta = [1., 1., 1., 1.]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \"\"\"VGGの特徴量\"\"\"\n",
    "        y1 = self.conv(\"conv1_2\")(self.conv(\"conv1_1\")(x), activation_fn=None)\n",
    "        x1 = avg_pool(tf.nn.relu(y1), ksize=2, stride=2)  # max?\n",
    "        \n",
    "        y2 = self.conv(\"conv2_2\")(self.conv(\"conv2_1\")(x1), activation_fn=None)\n",
    "        x2 = avg_pool(tf.nn.relu(y2), ksize=2, stride=2)  # max?\n",
    "        \n",
    "        y3 = self.conv(\"conv3_3\")(self.conv(\"conv3_2\")(self.conv(\"conv3_1\")(x2)), activation_fn=None)\n",
    "        x3 = avg_pool(tf.nn.relu(y3), ksize=2, stride=2)  # max?\n",
    "        \n",
    "        y4 = self.conv(\"conv4_3\")(self.conv(\"conv4_2\")(self.conv(\"conv4_1\")(x3)), activation_fn=None)\n",
    "        \n",
    "        return [y1, y2, y3, y4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: よさげにする\n",
    "def inner_product_matrix(y):\n",
    "    _, height, width, ch_num = y.get_shape().as_list()\n",
    "    y_reshaped = tf.reshape(y, [-1, height * width, ch_num])\n",
    "    return tf.matmul(y_reshaped, y_reshaped, adjoint_a=True) / (height * width * ch_num)\n",
    "# TODO: version依存\n",
    "\n",
    "\n",
    "class Generator:\n",
    "    def __init__(self, base_model, img_orig, img_style, config):\n",
    "        # 特徴抽出を行う\n",
    "        mids_orig = base_model(img_orig)\n",
    "        mids_style = base_model(img_style)\n",
    "        \n",
    "        # 損失関数に使うものを作る\n",
    "        prods_style = [inner_product_matrix(y) for y in mids_style]\n",
    "        \n",
    "        # img_genを初期化する\n",
    "        img_gen = tf.Variable(tf.random_uniform(config.output_shape, -20, 20))  # rank 4で無くてもいい説\n",
    "        \n",
    "        self.img_gen = img_gen\n",
    "        mids = base_model(img_gen)\n",
    "        \n",
    "        self.loss = []\n",
    "        self.loss1 = []\n",
    "        self.loss2 = []\n",
    "        \n",
    "        for i, (mid, mid_orig, mid_style, prod_style, alpha, beta) in enumerate(\n",
    "            zip(mids, mids_orig, mids_style, prods_style, base_model.alpha, base_model.beta)):\n",
    "            # 損失関数の定義\n",
    "            shape1 = mid.get_shape().as_list()\n",
    "            loss1 = config.lam * tf.nn.l2_loss(mid - mid_orig) / np.prod(shape1)\n",
    "            shape2 = prod_style.get_shape().as_list()\n",
    "            loss2 = beta * tf.nn.l2_loss(inner_product_matrix(mid) - prod_style) / np.prod(shape2)\n",
    "            if alpha != 0.0:\n",
    "                loss = loss1 * alpha + loss2 / len(mids)\n",
    "            else:\n",
    "                loss = loss2 / len(mids)\n",
    "            self.loss.append(loss)\n",
    "            self.loss1.append(loss1 * alpha)\n",
    "            self.loss2.append(loss2 / len(mids))\n",
    "        self.total_loss = sum(self.loss)  # tfのを使うべき？\n",
    "        self.total_train = config.optimizer.minimize(self.total_loss)\n",
    "        clipped = tf.clip_by_value(self.img_gen, -120., 136.)  # 要らない？\n",
    "        self.clip = tf.assign(self.img_gen, clipped)\n",
    "        \n",
    "    def generate(self, config):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            print(\"start\")\n",
    "            # 学習開始\n",
    "            for i in range(config.iteration):\n",
    "                sess.run([self.total_train, self.clip])\n",
    "                if (i + 1) % 50 == 0:\n",
    "                    # l, l1, l2 = sess.run([self.loss, self.loss1, self.loss2])\n",
    "                    # print(\"%d| loss: %f, loss1: %f, loss2: %f\" % (i + 1, sum(l), sum(l1), sum(l2)))\n",
    "                    # for l_, l1_, l2_ in zip(l, l1, l2):\n",
    "                    #   print(\"\\tloss: %f, loss1: %f, loss2: %f\" % (l_, l1_, l2_))\n",
    "                    self.save_image(sess, config.save_path % (i + 1))\n",
    "                    \n",
    "    def save_image(self, sess, path):\n",
    "        data = sess.run(self.img_gen)[0]\n",
    "        data = transform_from_train(data)\n",
    "        img = Image.fromarray(data.astype(np.uint8))\n",
    "        print(\"save %s\" % path)\n",
    "        img.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_model(model_name, **args):\n",
    "    if model_name == 'nin':\n",
    "        return NIN(**args)\n",
    "    if model_name == 'vgg':\n",
    "        return VGG(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 設定\n",
    "# modelを読み込む\n",
    "\n",
    "\n",
    "class Config:\n",
    "    batch_size = 1\n",
    "    iteration = 5000\n",
    "    lr = 4.0\n",
    "    lam = 0.005\n",
    "    width = 100\n",
    "    height = 100\n",
    "    output_shape = [batch_size, height, width, 3]\n",
    "    output_dir = \"_output\"\n",
    "    model = \"nin\"\n",
    "    original_image = \"./tmp/cat.png\"\n",
    "    style_image = \"./tmp/gogh.png\"\n",
    "    # model = \"vgg\"\n",
    "    save_path = os.path.expanduser(os.path.join(output_dir, \"%05d.png\"))\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    no_resize_style = False  # Trueにすると画風画像をリサイズせずに利用する（開始が遅くなる）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model... nin_imagenet.caffemodel\n"
     ]
    }
   ],
   "source": [
    "# 画像生成\n",
    "config = Config()\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "model = generate_model(config.model)\n",
    "\n",
    "# nin = generate_model('nin')\n",
    "# vgg = generate_model('vgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_orig = load_image(config.original_image, [config.width, config.height])\n",
    "img_style = load_image(config.style_image, [config.width, config.height] if not config.no_resize_style else None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "save _output/00050.png\n",
      "save _output/00100.png\n",
      "save _output/00150.png\n",
      "save _output/00200.png\n",
      "save _output/00250.png\n",
      "save _output/00300.png\n",
      "save _output/00350.png\n",
      "save _output/00400.png\n",
      "save _output/00450.png\n",
      "save _output/00500.png\n",
      "save _output/00550.png\n",
      "save _output/00600.png\n",
      "save _output/00650.png\n",
      "save _output/00700.png\n",
      "save _output/00750.png\n",
      "save _output/00800.png\n",
      "save _output/00850.png\n",
      "save _output/00900.png\n",
      "save _output/00950.png\n",
      "save _output/01000.png\n",
      "save _output/01050.png\n",
      "save _output/01100.png\n",
      "save _output/01150.png\n",
      "save _output/01200.png\n",
      "save _output/01250.png\n",
      "save _output/01300.png\n",
      "save _output/01350.png\n",
      "save _output/01400.png\n",
      "save _output/01450.png\n",
      "save _output/01500.png\n",
      "save _output/01550.png\n",
      "save _output/01600.png\n",
      "save _output/01650.png\n",
      "save _output/01700.png\n",
      "save _output/01750.png\n",
      "save _output/01800.png\n",
      "save _output/01850.png\n",
      "save _output/01900.png\n",
      "save _output/01950.png\n",
      "save _output/02000.png\n",
      "save _output/02050.png\n",
      "save _output/02100.png\n",
      "save _output/02150.png\n",
      "save _output/02200.png\n",
      "save _output/02250.png\n",
      "save _output/02300.png\n",
      "save _output/02350.png\n",
      "save _output/02400.png\n",
      "save _output/02450.png\n",
      "save _output/02500.png\n",
      "save _output/02550.png\n",
      "save _output/02600.png\n",
      "save _output/02650.png\n",
      "save _output/02700.png\n",
      "save _output/02750.png\n",
      "save _output/02800.png\n",
      "save _output/02850.png\n",
      "save _output/02900.png\n",
      "save _output/02950.png\n",
      "save _output/03000.png\n",
      "save _output/03050.png\n",
      "save _output/03100.png\n",
      "save _output/03150.png\n",
      "save _output/03200.png\n",
      "save _output/03250.png\n",
      "save _output/03300.png\n",
      "save _output/03350.png\n",
      "save _output/03400.png\n",
      "save _output/03450.png\n",
      "save _output/03500.png\n",
      "save _output/03550.png\n",
      "save _output/03600.png\n",
      "save _output/03650.png\n",
      "save _output/03700.png\n",
      "save _output/03750.png\n",
      "save _output/03800.png\n",
      "save _output/03850.png\n",
      "save _output/03900.png\n",
      "save _output/03950.png\n",
      "save _output/04000.png\n",
      "save _output/04050.png\n",
      "save _output/04100.png\n",
      "save _output/04150.png\n",
      "save _output/04200.png\n",
      "save _output/04250.png\n",
      "save _output/04300.png\n",
      "save _output/04350.png\n",
      "save _output/04400.png\n",
      "save _output/04450.png\n",
      "save _output/04500.png\n",
      "save _output/04550.png\n",
      "save _output/04600.png\n",
      "save _output/04650.png\n",
      "save _output/04700.png\n",
      "save _output/04750.png\n",
      "save _output/04800.png\n",
      "save _output/04850.png\n",
      "save _output/04900.png\n",
      "save _output/04950.png\n",
      "save _output/05000.png\n"
     ]
    }
   ],
   "source": [
    "# config = Config()\n",
    "generator = Generator(model, img_orig, img_style, config)\n",
    "\n",
    "generator.generate(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
